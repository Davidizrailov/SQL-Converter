import re
import os
import pandas as pd


complexity_patterns = {
    "Multiple Data Sources": r"\bFILE\b.*\b[A-Z]+\b",  # Matches FILE statements with data source names
    "Complex Data Transformations": r"\bMOVE\b.*\bTO\b.*",  # Matches data transformation using MOVE or similar keywords
    "Sort Operations": r"\bSORT\b.*",  # Matches SORT operation
    "Join Operations": r"\bJOIN\b.*",  # Matches JOIN operation
    "Conditional Logic (IF)": r"\bIF\b.*",  # Matches IF conditions
    "Conditional Logic (WHEN)": r"\bWHEN\b.*",  # Matches WHEN conditions
    "Loops or Iterative Logic": r"\bPERFORM\b.*\bUNTIL\b",  # Matches loops or iterative constructs
    "Subroutines and Procedures": r"\bPROC\b.*",  # Matches procedure definitions
    "Error Handling or Input Validation": r"\bERROR\b|\bVALIDATE\b",  # Matches error handling or input validation logic
    "External Function Calls": r"\bCALL\b.*\b[A-Z]+\b",  # Matches external function or system calls
}

complexity_cols = ["Object Path", "Object Name", "Complexity Score", "Data Sources", "Data Transformations", 
                   "Sort Operations", "Join Operations", "Conditionals", "Loops", "Subroutines", 
                   "Error Handling", "External Calls"]

df_complexity = pd.DataFrame(columns=complexity_cols)

def count_complexity_instances(code, patterns):
    counts = {}
    for description, pattern in patterns.items():
        matches = re.findall(pattern, code, re.IGNORECASE)
        counts[description] = len(matches)
    return counts

def list_files_recursively(folder_path):
    all_files = []
    for root, dirs, files in os.walk(folder_path):
        for file in files:
            all_files.append(os.path.join(root, file))
    return all_files

folder_path = "files/content_assessment/DEMO_DB"
all_files = list_files_recursively(folder_path)

for file_path in all_files:
    # OBJECT TYPE
    ext = file_path.split(".")[-1]
    if ext == "et":
        filename = os.path.basename(file_path)
        
        with open(file_path, 'r') as file:
            content = file.read()
        
        complexity_counts = count_complexity_instances(content, complexity_patterns)
        
        complexity = {
            "Object Path": file_path,
            "Object Name": filename,
            "Data Sources": complexity_counts.get("Multiple Data Sources", 0),
            "Data Transformations": complexity_counts.get("Complex Data Transformations", 0),
            "Sort Operations": complexity_counts.get("Sort Operations", 0),
            "Join Operations": complexity_counts.get("Join Operations", 0),
            "Conditionals": complexity_counts.get("Conditional Logic (IF)", 0) + complexity_counts.get("Conditional Logic (WHEN)", 0),
            "Loops": complexity_counts.get("Loops or Iterative Logic", 0),
            "Subroutines": complexity_counts.get("Subroutines and Procedures", 0),
            "Error Handling": complexity_counts.get("Error Handling or Input Validation", 0),
            "External Calls": complexity_counts.get("External Function Calls", 0),
        }
        
        complexity["Complexity Score"] = sum([
            complexity["Data Sources"],
            complexity["Data Transformations"],
            complexity["Sort Operations"],
            complexity["Join Operations"],
            complexity["Conditionals"],
            complexity["Loops"],
            complexity["Subroutines"],
            complexity["Error Handling"],
            complexity["External Calls"]
        ])
        
        df_complexity = pd.concat([df_complexity, pd.DataFrame([complexity])], ignore_index=True)

# Save the DataFrame to a CSV file
df_complexity.to_csv(r"files/content_assessment/ComplexityET.csv", index=False)
print("Done!")
